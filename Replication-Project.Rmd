---
title: "Replication-Project.Rmd"
author: "Sophie Li"
date: "5/5/2021"
output:
  pdf_document: default
  fig_cap: yes
  keep_tex: yes
  html_document: default
  word_document: default
header-includes:
    - \usepackage{caption}
    - \usepackage{dcolumn}
    - \usepackage{float}
    - \floatplacement{figure}{H}
---

\captionsetup[table]{labelformat=empty}

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, fig.pos = "h")

library(tidyverse)
library(stargazer)
library(multcomp)
library(car)
library(haven)
library(sjlabelled)
library(nnet)
library(gt)
library(kableExtra)
library(mice)
```

# Introduction

For my final project, I replicated the analysis performed by Abhit Bhandari in
his paper "Political Determinants of Economic Exchange: Evidence from a Business
Experiment in Senegal." In his experiment, Bhandari aimed to evaluate whether
political connections and formal contracts impact the exchange of goods in
Dakar, Senegal. To do this, he created his own business in Dakar that sold phone
credits.

*All data and code in this paper can be found at the following link:*
*https://doi.org/10.7910/DVN/UIFXGX*

# Senegal as a Place of Business

According to Bhandari, Senegal has weak legal institutions and
consistently ranks poorly in work indexes for ease of doing business and
enforcement of legal contracts. Furthermore, contractual
enforcement becomes more complicated when the involved parties possess political
connections. Per Bhandari, possessing political connections in Senegal
affords one preferential treatment, including situations such as contractual
enforcement. In essence, if a person breaks a legal contract, they are less
likely to be held accountable if they hold political connections.

# Bhandari's Hypotheses

Given this background information, Bhandari poses the following three
hypotheses: The first hypothesis is that sellers who possess political
connections will deter buyers from purchasing their goods. The second hypothesis
is that formal legal contracts between sellers and buyers will increase the
probability that a buyer purchases goods from the seller. The third hypothesis
is that buyers have a higher probability of purchasing goods if they hold
political connections and the seller in question does not hold political
connections; conversely, buyers have a lower probability of purchasing goods if
the seller possess political connections and the buyer does not.

Below, I have replicated Table 1 of Bhandari's paper, which shows his
theoretical predictions.

```{r table1, always_allow_html: true}

df_t1 <- matrix(nrow = 2,
                 ncol = 2,
                 c("Intermediate probability of purchase", 
                                   "Low probability of purchase",
                                   "High probability of purchase", 
                                   "Intermediate probability of purchase"),
                dimnames = list(c("Seller is not politically connected", 
                                  "Seller is politically connected"),
                c("No", "Yes")))

kable(df_t1, 
      caption = "Table 1: Theoretical Predictions Under Asymmetric Political 
      Connections") %>%
  kable_styling(font_size = 8, latex_options = "hold_position") %>%
  add_header_above(c(" " = 1, "Buyer is politically connected" = 2))

```


# Bhandari's Experiment Setup

Bhandari registered an official business in Senegal that offered phone credits.
Since part of his hypothesis involved sellers' signaling their political
connections to buyers, he arranged for his nine hired employees to intern at
a municipal council in Senegal. Afterwards, his employees began
official employment.

Pertaining to treatment groups, Bhandari utilized a "factorial design" that
involved three "treatment arms" which sought to assess how political
connections and legal contracts would impact the exchange of goods between
buyers and sellers. 

The first treatment arm involved sellers revealing their political connections
via bringing up their prior internship experience while talking to buyers (Note:
according to Bhandari, it is customary for Senegal citizens to engage in long
introductions when partaking in household business transactions).

The second treatment arm involved sellers' requiring a formal contract signed
between the seller and buyer for the transaction. This contract pertained to
the transaction details, payment types, and product delivery information.

The third treatment arm involved sellers' providing an optional formal contract
to the buyer. In this scenario, buyers could chose to receive the same contract
described above in exchange for a small fee.

A factorial experiment involves analyzing each level of independent factors in
every combination possible with levels of other independent factors (Source:
Penn State college of Health and Human Development). For example, in Bhandari's
experiment, factorial design gives us six different treatment groups (including
the control group). This is because we have three types of contract availability
(no contract, mandatory contract, and an optional contract). Additionally, for
each of these treatments, the sellers either signaled or did not signal their
connections. Hence, 3 X 2 = 6 different permutations.

Below, I replicated Bhandari's Table 2, which illustrates the six
different treatment groups in his experiment.

```{r table2, always_allow_html: true}

df_t2 <- matrix(nrow = 2,
                 ncol = 3,
                 c("Pure control",
                   "Required contract",
                   "Optional contract",
                   "Connection",
                   "Connection + required contract",
                   "Connection + optional contract"),
                dimnames = list(c("Signaled connections", 
                                  "Did not signal connections"),
                c("No contract", "Contract (required)", "Contract (optional)")))

kable(df_t2, 
      caption = "Table 2: Treatment Groups") %>%
  kable_styling(font_size = 8,
                latex_options = "hold_position") %>%
  add_header_above(c(" " = 1, "Contract Availability" = 3))

```
# Block Randomization

For his experiment, Bhandari utilized block randomization in order to reduce
sampling bias, as sampling bias may skewed the experiment's results. He
conducted the experiment across three housing communes. Each of the three
communes had exposure to all six treatment types. In essence, Bhandari's
employees went to various homes in each commune, and in each home visit, they
were randomly assigned a certain treatment to provide. To ensure treated
individuals' responses were independent and identically distributed (IID),
Bhandari instructed sellers to visit houses that were a certain distance away
from each other (in that way, neighbors wouldn't gossip with each other about
the new phone credit business) as well as only sell products to one person in
each household (so that household members wouldn't confer and influence each
others' responses).

# Data Collection

Data was collected in two waves. The first wave was the selling stage (i.e.,
sellers selling phone credits to prospective buyers). The second wave was post-
transaction, when buyers were surveyed about topics such as their perceptions
of sellers' competency, trustworthiness, etc.

# Measuring Primary Outcomes

Bhandari aimed to measure two outcomes: the buyers' willingness to purchase the
product, as well as the amount of risk buyers were willing to take on in the
transaction.

In order to capture the salient data, Bhandari's business offered three
different phone credit packages. The first package cost 700 West African CFA
francs and offered almost instant delivery of a small amount of phone credits.
The second package was cheaper, offered more phone credits, but was subject to a
3-day delivery delay after purchase (for which buyers were told was due to
administrative processing). The third package was the most expensive option and
also would be delivered after 3 days; however it also offered the greatest
amount of phone credits per currency unit of all the packages available.

Below I have replicated Table 3 of Bhandari's paper, which showcases the full
inventory of phone credit packages that his business offered as well as the
associated risks of each package.

```{r table3, always_allow_html: true}

df_t3 <- data.frame(purchase_level = c('Declined deal','No delay','Delay ($)', 
                                       "Delay ($$$)"),
                    cost = c("-", 700, 500, "1,000"),
                    credits_received = c("-", "1,000", "1,500", "3,000"),
                    credit_arrival = c("-", "Several minutes", "In 3 days", 
                                       "In 3 days"),
                    risk_type = c("-", "Risk of substandard quality", 
                    "Risk of substandard quality and nondelivery", 
                    "Risk of substandard quality and nondelivery"))

kable(head(df_t3, 5), booktabs = T,
      col.names = c(purchase_level = "Purchase level",
             cost = "Cost (CFA)",
             credits_received = "Credits received (CFA)",
             credit_arrival = "When phone credit arrived",
             risk_type = "Type of risk"),
      caption = "Table 3: Phone Credit Purchase Options") %>%
  kable_styling(font_size = 8, latex_options = "hold_position")


```

# Bhandari's Findings

Bhandari ultimately found that employees who signaled connections caused buyers
to be less likely to purchase a service. This is likely due to buyers being
hesitant that sellers with political connections are less likely to be held
accountable if they breach a contract. Additionally, the presence of a formal
sales contract induced buyers to be more willing to purchase a service; however,
this effect was larger for buyers with political connections. This result may be
due to politically connected buyers feeling more secure that they have the legal
system's support, compared to individuals who do not have such connections.


# Additional Model Replications

```{r datacleaning}

# DATA CLEANING IS ORIGINAL AUTHOR'S CODE
# Le said this was fine, and I trust Le 110%

# I did also not format the data to be prettier because that caused it to break

# Load data (alter file path as needed)
load("Author_Files/data_source.rdata")

# Renaming data
data <- data_source

# Prepare data for main analysis ------------------------------------------

# Indicator variable coded 1 if respondent's ethnicity matches seller's ethnicity
data <- data %>% mutate(coethnic = ifelse(trans.enum==1 & ethnicity==4 |
                                            trans.enum==2 & ethnicity==3 |
                                            trans.enum==3 & ethnicity==5 |
                                            trans.enum==4 & ethnicity==1 |
                                            trans.enum==5 & ethnicity==4 |
                                            trans.enum==6 & ethnicity==1 |
                                            trans.enum==7 & ethnicity==4 |
                                            trans.enum==8 & ethnicity==2 |
                                            trans.enum==9 & ethnicity==4, 
                                          1, 0))

# Indicator variable coded 1 if respondent's religion matches seller's (does 
# not include Muslims not belonging to a brotherhood)
data <- data %>% mutate(coreligion = ifelse(trans.enum==2 & religion==4 |
                                              trans.enum==3 & religion==1 |
                                              trans.enum==4 & religion==3 |
                                              trans.enum==8 & religion==2, 
                                            1, 0))

# Indicator variable coded 1 if respondent is coethnic and/or coreligious to seller
data <- data %>% mutate(coethnicreligion = ifelse(coethnic==1 | coreligion==1, 1, 0))

# Indicator variable coded 1 if respondent purchased phone credit with delayed delivery
data <- data %>% mutate(subscription_trust = ifelse(subscription>1, 1, 0))

# Indicator variable coded 1 if respondent purchased any level of phone credit 
data <- data %>% mutate(purchased = ifelse(subscription==1 | subscription==2 | subscription==3,
                                           1, 0))

# Indicator variable coded 1 if respondent attrited (i.e. did not complete endline survey)
data <- data%>%mutate(attrit = ifelse(data$missing_endline==1,1, 0))

# re-assigning data before the mean imputation for the extension part of this
# paper

data_for_mice <- data %>% mutate(pool_treatment_group = ifelse(treatment_group==1 | treatment_group==3, 1,
                                                      ifelse(treatment_group==4 | treatment_group==6, 3,
                                                             ifelse(treatment_group==2, 2, 
                                                                    ifelse(treatment_group==5, 4, NA)))))%>% mutate(pool_T1 = ifelse(pool_treatment_group == 3 | pool_treatment_group == 4, 1,0)) %>%
  mutate(pool_T2 = ifelse(pool_treatment_group == 2 | pool_treatment_group == 4, 1,0))

# Imputing missing education values -- center of scale
data$educ_level[data$educ_level==98 | data$educ_level == 99
                       | data$missing_endline==1] <- 3

# Imputing missing or incorrect age values -- mean
data$descriptives.age[data$descriptives.age==0 | data$descriptives.age ==3 | 
                        data$missing_endline==1] <- mean(data$descriptives.age, na.rm=T)

# Imputing missing student indicator -- mean
data$student[data$missing_endline==1] <- mean(data$student, na.rm=T)

# Imputing missing employed indicator -- mean
data$employed[data$missing_endline==1] <- mean(data$employed, na.rm=T)

# Imputing missing coethnic or coreligious indicator -- mean
data$coethnicreligion[data$missing_endline==1] <- mean(data$coethnicreligion, na.rm=T)

# Imputing missing belief in sellers' connections -- mean
data$thinks_seller_is_connected[data$thinks_seller_is_connected > 3 | is.na(data$thinks_seller_is_connected)==T] <- mean(data$thinks_seller_is_connected[data$thinks_seller_is_connected < 2], na.rm=T)


# Indicator variables for pooled treatment group
data <- data %>% mutate(pool_treatment_group = ifelse(treatment_group==1 | treatment_group==3, 1,
                                                      ifelse(treatment_group==4 | treatment_group==6, 3,
                                                             ifelse(treatment_group==2, 2, 
                                                                    ifelse(treatment_group==5, 4, NA)))))
data <- data %>% mutate(pool_T1 = 
                          ifelse(pool_treatment_group == 3 | pool_treatment_group == 4, 1,0)) %>%
  mutate(pool_T2 = 
           ifelse(pool_treatment_group == 2 | pool_treatment_group == 4, 1,0))

# Imputing missing values for trust and quality questions -- means
data$seller_quality[data$seller_quality==98 | is.na(data$seller_quality)==T] <- mean(data$seller_quality, na.rm=T)
data$seller_trust[data$seller_trust==98 | is.na(data$seller_trust)==T] <- mean(data$seller_trust, na.rm=T)
data$`enum_questions:follow_up_questions`[is.na(data$`enum_questions:follow_up_questions`==T)] <- mean(data$`enum_questions:follow_up_questions`, na.rm=T)
data$`enum_questions:follow_up_polite`[is.na(data$`enum_questions:follow_up_polite`==T)] <- mean(data$`enum_questions:follow_up_polite`, na.rm=T)
data$`enum_questions:follow_up_suspicious`[is.na(data$`enum_questions:follow_up_suspicious`==T)] <- mean(data$`enum_questions:follow_up_suspicious`, na.rm=T)

# Saving dataset for analysis (alter file path as needed)
save(data, file="Author_Files/data_analysis.RData")

```

I replicated 15 of Bhandari's models, which made up 3 tables total. 
*Note: In this paper, Bhandari uses exclusively OLS linear regressions.*

Below, I have replicated Table 4, which Bhandari utilizes to prove the validity
of the experiment set-up (i.e., that sellers' signalling political connections
actually led buyers to believe the seller possessed political connections).

In creating this model, I regressed the `thinks_seller_is_connected` outcome
variable on several covariates: The covariate we're most interested in is
`pool_T1`, which is a binary indicator for whether the seller signaled political
connections. In essence, we want to see, when the seller talks about their 
prior work experience with the municipal government, does that cause the buyer
to believe the seller holds political connections? Bhandari is trying to prove
this is the case because it is only then he can measure how political connections
can influence the exchange of goods. After all, if buyers don't think sellers
have political connections even if the sellers signal it, then this experiment
would be ineffective at capturing political connections' effects on the exchange
of goods.

All other covariates consisted fixed effects from block randomization
and enumerators as well as controls.

List of additional covariates: 
-`enum`, which indicated which enumerator surveyed the buyer after the
transaction period (range: 1-9)
-`block.id`, which randomization block the survey respondent resides in (range:
1-243)
-`descriptives.age`, which refers to the survey respondent's age
-`gender`, which refers to the survey respondent's gender
-`educ_level`, which refers to the survey respondent's highest level of
completed education (range: 1-5)
-`employed`, binary indicator on whether the survey respondent is employed
-`student`, binary indicator on whether the survey respondent is a student
-`coethnicreligion`, binary indicator on whether the survey respondent and the
seller shared the same ethnicity and/or religion

In replicating this model, I also included the interaction between `pool_T1` and
`coethnicreligion`, which served to examine if sharing the same religion or 
ethnic affects how a buyer perceives a sellers' signaling of political 
connections.

From just reading the methodology in Bhandari's paper alone, I was able to
capture somewhat similar coefficients in my model. However, I ultimately had to
glance at Bhandari's code to see what I was missing, which ended up being the
factorization of `enum`, `blockid`, `educ_level`. Factorization of these three
variables was definitely important since otherwise, they would be erroneously
treated as numeric variables (which did end up skewing my regression
outputs). Additionally, I did not include the interaction between `pool_T1` and
`coethnicreligion` in my initial model.

However, in my initial model, I did include the `religion` and the `ethnicty` of
the survey respondent, since I would consider them to be a part of the fixed
effects. I assume Bhandari did not include them because he thought 
`coethnicreligion` would sufficiently cover that domain.

```{r table4, results = 'asis', warning = FALSE}

# Turning these variables into factors because otherwise, they'll be
# interpreted as numeric
data_factored <- data %>%
  mutate(enum = as.factor(enum),
         blockid = as.factor(blockid),
         educ_level = as.factor(educ_level))

# Model
table4 <- lm(thinks_seller_is_connected ~ pool_T1 + gender + blockid + enum  + 
                descriptives.age + employed + student + educ_level +
                coethnicreligion*pool_T1, data = data_factored)

# Calculating the control group outcome mean and std, which were also included
# on the original Table 4 in Bhandari's paper
control_group_outcomes <- data_factored %>% 
  group_by(pool_T1) %>% 
  summarise(control_group_outcome_mean = 
              round(mean(thinks_seller_is_connected), 3),
            control_group_outcome_std = 
              round(sd(thinks_seller_is_connected), 3), .groups = "drop") %>%
  
  #Gives us the top row, in which the seller did not signal political connections
  head(1)

stargazer(table4, omit = c(2:262),
          title = "Table 4: Buyer Belief of Seller Connections Driven by
          Connection Signal",
          covariate.labels = c("Connection signaled"),
          dep.var.labels = "Buyer believes seller has political connections",
          add.lines = list(c("Control group outcome mean", 
                             control_group_outcomes$control_group_outcome_mean),
                             c("Control group outcome std. dev",
                             control_group_outcomes$control_group_outcome_std),
                           c("Outcome range", "{0, 1}"),
                           c("Fixed effects", "Yes"),
                           c("Controls", "Yes")), header=FALSE, 
          omit.stat=c("ser","f", "ll","rsq", "adj.rsq"))

```

As you can see from this table, buyers who were treated to the seller's
signaling of political connections were 18.8% more likely to believe the
seller possessed political connections compared to buyers who did not receive
the treatment.

I next replicated Table 5 of Bhandari's paper, which analyzed how the three
treatments (signaling political connections, requiring a contract, offering an
optional contract) affected whether buyers purchased phone credits as well as
the level of risk buyers were willing to engage in for their purchase.

This table contains four different models. The first model (1) regresses the
`purchased` variable (if a buyer purchased anything) over several covariates,
including signaling political connection, requiring a contract, offering an
optional contract, interaction terms between signaling political connections and
the contracts, as well as various fixed effects and constants (same as those
used for Table 4).

This first model uses "unpooled" data, which means that the optional contract is
separate from not offering a contract at all. However, Bhandari states that the
optional contract treatment arm is "conceptually similar" to not offering a
contract at all. Hence, in Model 2, the regression is identical to Model 1,
except the optional contract variables has been "pooled" with the control group
(not offering a contact at all). Hence, we do not see a model output for the
optional contract and its interaction with political connection signal for Model
2.

Models 3 and 4 follow the same philosophy, except this time, the outcome
variable is if the buyer ended up purchasing a phone credit service that
entailed a delay (i.e, a higher-risk purchase). Model 3 is a linear regression
with the `optional contract` variable unpooled, whereas Model 4 has `optional
contract` pooled with the control group.


```{r table5, results = 'asis', warning = FALSE}

# Model A: Purchased at all (unpooled)
model_a <- lm(purchased ~ T1 + T2 + T3 + T1*T2 + T1*T3 + gender + blockid + 
                enum + descriptives.age + employed + student + educ_level +
                coethnicreligion*T1 + coethnicreligion*T2 + coethnicreligion*T3, 
              data = data_factored)

  # Calculating the control group outcome mean and std for unpooled, purchased 
  # at all
  control_group_outcomes_a <- data_factored %>% 
    group_by(T1, T2, T3) %>% 
    summarise(control_group_outcome_mean = round(mean(purchased), 3),
            control_group_outcome_std = round(sd(purchased), 3), 
            .groups = "drop") %>%
    head(1)

# Model B: Purchased at all (pooled)
model_b_data <- subset(data_factored, select = c("pool_T1", "pool_T2", "gender", 
                                                 "blockid", "enum", 
                                                 "descriptives.age", "employed",
                                                 "student", "educ_level",
                                                 "coethnicreligion", 
                                                 "purchased",
                                                 "subscription_trust")) %>%
  mutate(T1 = pool_T1,
         T2 = pool_T2)

model_b <- lm(purchased ~ T1 + T2 + T1*T2 + gender + blockid + 
                enum + descriptives.age + employed + student + educ_level +
                coethnicreligion*T1 + coethnicreligion*T2, 
              data = model_b_data)

  # Calculating the control group outcome mean and std for unpooled, purchased 
  # at all
  control_group_outcomes_b <- data_factored %>% 
    group_by(pool_T1, pool_T2) %>% 
    summarise(control_group_outcome_mean = round(mean(purchased), 3),
            control_group_outcome_std = round(sd(purchased), 3), 
            .groups = "drop") %>%
    head(1)

# Model C: Purchased with delay (unpooled)
model_c <- lm(subscription_trust ~ T1 + T2 + T3 + T1*T2 + T1*T3 + gender + 
              blockid + enum + descriptives.age + employed + student + 
              educ_level + coethnicreligion*T1 + coethnicreligion*T2 + 
              coethnicreligion*T3, data = data_factored)

  # Calculating the control group outcome mean and std for unpooled, purchased 
  # at all
  control_group_outcomes_c <- data_factored %>% 
    group_by(T1, T2, T3) %>% 
    summarise(control_group_outcome_mean = round(mean(subscription_trust), 3),
            control_group_outcome_std = round(sd(subscription_trust), 3), 
            .groups = "drop") %>%
    head(1)

# Model D: Purchased with delay (pooled)
model_d <- lm(subscription_trust ~ T1 + T2 + T1*T2 + 
                gender + blockid + 
                enum + descriptives.age + employed + student + educ_level +
                coethnicreligion*T1 + coethnicreligion*T2, 
              data = model_b_data)

  # Calculating the control group outcome mean and std for unpooled, purchased 
  # at all
  control_group_outcomes_d <- data_factored %>% 
    group_by(pool_T1, pool_T2) %>% 
    summarise(control_group_outcome_mean = round(mean(subscription_trust), 3),
            control_group_outcome_std = round(sd(subscription_trust), 3), 
            .groups = "drop") %>%
    head(1)
  
# Fusing all four models together
stargazer(model_a, model_b, model_c, model_d,
          covariate.labels = c("Political connection signaled",
                               "Required contract",
                               "Optional contract",
                               "Political connection signal x required contract",
                               "Political connection signal x optional contract"),
          omit = c("gender", "blockid", "enum", "descriptives.age",  
                   "employed","student", "educ_level","coethnicreligion",
                   "Constant"),
          title = "Table 5: Average Treatment Effects",
          column.labels = c("Unpooled", 
                            "Pooled",
                            "Unpooled",
                            "Pooled"),
          dep.var.labels = c("Purchased at all", 
                             "Purchased with Delay"),
          add.lines = list(c("Control group outcome mean", 
                             control_group_outcomes_a$control_group_outcome_mean,
                             control_group_outcomes_b$control_group_outcome_mean,
                             control_group_outcomes_c$control_group_outcome_mean,
                             control_group_outcomes_d$control_group_outcome_mean),
                             c("Control group outcome std. dev",
                             control_group_outcomes_a$control_group_outcome_std,
                             control_group_outcomes_b$control_group_outcome_std,
                             control_group_outcomes_c$control_group_outcome_std,
                             control_group_outcomes_d$control_group_outcome_std),
                           c("Fixed effects", "Yes"),
                           c("Controls", "Yes")),
          header = FALSE,
          single.row = FALSE, 
          no.space = FALSE, 
          column.sep.width = "2pt",
          font.size = "small",
          omit.stat=c("ser","f", "ll","rsq", "adj.rsq"))
```

We see in the unpooled model (1) that, when a political connection is signaled,
then buyers are on average 5.3 less likely to purchase a phone credit service.
In the pooled model (3), when a political connection is signaled, buyers are on
average 4.4 less likely to purchase a phone credit service.

Additionally, in the unpooled model (3), we see that when the seller requires a
formal contract for the transaction, buyers are 10.4% more likely to purchase a
phone credit package that entails a delay. Similarly, in the pooled model, we
see that when the seller requires a formal contract for the transaction, buyers
are 7.5% more likely to purchase a phone credit package that entails a delay.

Overall, Table 5's results suggest that sellers' signalling political
connections has a negative influence on buyers' willingness to make a purchase.
In contrast, when the seller requires a formal contract, buyers are more willing
to buy more high-risk product options.

The final replication I conducted was Table 6 of Bhandari's paper, which
includes 10 models total. These models measure quality criteria of both
sellers and buyers.

```{r table6, results = 'asis', warning = FALSE}

# Renaming the enum questions variable names to make life easier
data_better_enum <- data_factored %>%
  rename(questions = `enum_questions:follow_up_questions`,
         polite = `enum_questions:follow_up_polite`,
         suspicious = `enum_questions:follow_up_suspicious`)

model_1 <- lm(seller_quality ~ pool_T1 + pool_T2 + + gender + 
                blockid + enum + descriptives.age + employed + student + 
                educ_level + coethnicreligion*pool_T1 + coethnicreligion*pool_T2, 
              data = data_better_enum)

model_2 <- lm(seller_quality ~ pool_T1 + pool_T2 + pool_T1*pool_T2 + + gender + 
                blockid + enum + descriptives.age + employed + student + 
                educ_level + coethnicreligion*pool_T1 + coethnicreligion*pool_T2, 
              data = data_better_enum)

model_3 <- lm(seller_trust ~ pool_T1 + pool_T2 + + gender + 
                blockid + enum + descriptives.age + employed + student + 
                educ_level + coethnicreligion*pool_T1 + coethnicreligion*pool_T2, 
              data = data_better_enum)

model_4 <- lm(seller_trust ~ pool_T1 + pool_T2 + pool_T1*pool_T2 + + gender + 
                blockid + enum + descriptives.age + employed + student + 
                educ_level + coethnicreligion*pool_T1 + coethnicreligion*pool_T2, 
              data = data_better_enum)

model_5 <- lm(questions ~ pool_T1 + pool_T2 + + gender + 
                blockid + enum + descriptives.age + employed + student + 
                educ_level + coethnicreligion*pool_T1 + coethnicreligion*pool_T2, 
              data = data_better_enum)

model_6 <- lm(questions ~ pool_T1 + pool_T2 + pool_T1*pool_T2 + + gender + 
                blockid + enum + descriptives.age + employed + student + 
                educ_level + coethnicreligion*pool_T1 + coethnicreligion*pool_T2, 
              data = data_better_enum)

model_7 <- lm(polite ~ pool_T1 + pool_T2 + + gender + 
                blockid + enum + descriptives.age + employed + student + 
                educ_level + coethnicreligion*pool_T1 + coethnicreligion*pool_T2, 
              data = data_better_enum)

model_8 <- lm(polite ~ pool_T1 + pool_T2 + pool_T1*pool_T2 + + gender + 
                blockid + enum + descriptives.age + employed + student + 
                educ_level + coethnicreligion*pool_T1 + coethnicreligion*pool_T2, 
              data = data_better_enum)

model_9 <- lm(suspicious ~ pool_T1 + pool_T2 + + gender + 
                blockid + enum + descriptives.age + employed + student + 
                educ_level + coethnicreligion*pool_T1 + coethnicreligion*pool_T2, 
              data = data_better_enum)

model_10 <- lm(suspicious ~ pool_T1 + pool_T2 + pool_T1*pool_T2 + + gender + 
                blockid + enum + descriptives.age + employed + student + 
                educ_level + coethnicreligion*pool_T1 + coethnicreligion*pool_T2, 
              data = data_better_enum)

# Calculating control group outcome mean and std. dev.

control_group_outcomes_1_2 <- data_better_enum %>% 
    group_by(pool_T1, pool_T2) %>% 
    summarise(control_group_outcome_mean = round(mean(seller_quality), 3),
            control_group_outcome_std = round(sd(seller_quality), 3), 
            .groups = "drop") %>%
    head(1)

control_group_outcomes_3_4 <- data_better_enum %>% 
    group_by(pool_T1, pool_T2) %>% 
    summarise(control_group_outcome_mean = round(mean(seller_trust), 3),
            control_group_outcome_std = round(sd(seller_trust), 3), 
            .groups = "drop") %>%
    head(1)

control_group_outcomes_5_6 <- data_better_enum %>% 
    group_by(pool_T1, pool_T2) %>% 
    summarise(control_group_outcome_mean = round(mean(questions), 3),
            control_group_outcome_std = round(sd(questions), 3), 
            .groups = "drop") %>%
    head(1)

control_group_outcomes_7_8 <- data_better_enum %>% 
    group_by(pool_T1, pool_T2) %>% 
    summarise(control_group_outcome_mean = round(mean(polite), 3),
            control_group_outcome_std = round(sd(polite), 3), 
            .groups = "drop") %>%
    head(1)

control_group_outcomes_9_10 <- data_better_enum %>% 
    group_by(pool_T1, pool_T2) %>% 
    summarise(control_group_outcome_mean = round(mean(suspicious), 3),
            control_group_outcome_std = round(sd(suspicious), 3), 
            .groups = "drop") %>%
    head(1)

# Combining everything together
stargazer(model_1, model_2, model_3, model_4, model_5, model_6, model_7,
          model_8, model_9, model_10,
          title = "Table 6: Quality Measures from Buyers and Sellers",
          covariate.labels = c("Political connection signaled",
                               "Formal contract",
                               "Political connection signal 
                               x formal contract"),
                    dep.var.labels = c("Seller's competence ", 
                                       "Seller's Trustworthiness", 
                                       "Buyer's \\# of questions", 
                                       "Buyer's politeness", 
                                       "Buyer's suspicion"),
          omit = c("gender", "blockid", "as.factor", "enum", "descriptives.age",  
                   "employed","student", "educ_level","coethnicreligion",
                   "Constant"),
          add.lines = list(c("Control group outcome mean", 
                             control_group_outcomes_1_2$control_group_outcome_mean,
                             control_group_outcomes_1_2$control_group_outcome_mean,
                             control_group_outcomes_3_4$control_group_outcome_mean,
                             control_group_outcomes_3_4$control_group_outcome_mean,
                             control_group_outcomes_5_6$control_group_outcome_mean,
                             control_group_outcomes_5_6$control_group_outcome_mean,
                             control_group_outcomes_7_8$control_group_outcome_mean,
                             control_group_outcomes_7_8$control_group_outcome_mean,
                             control_group_outcomes_9_10$control_group_outcome_mean,
                             control_group_outcomes_9_10$control_group_outcome_mean,
                             c("Control group outcome std. dev",
                             control_group_outcomes_1_2$control_group_outcome_std,
                             control_group_outcomes_1_2$control_group_outcome_std,
                             control_group_outcomes_3_4$control_group_outcome_std,
                             control_group_outcomes_3_4$control_group_outcome_std,
                             control_group_outcomes_5_6$control_group_outcome_std,
                             control_group_outcomes_5_6$control_group_outcome_std,
                             control_group_outcomes_7_8$control_group_outcome_std,
                             control_group_outcomes_7_8$control_group_outcome_std,
                             control_group_outcomes_9_10$control_group_outcome_std,
                             control_group_outcomes_9_10$control_group_outcome_std)),
                           c("Fixed effects", "Yes"),
                           c("Controls", "Yes")),
          font.size = "tiny",
          column.sep.width = "1pt",
          header = FALSE,
          omit.stat=c("ser","f", "ll","rsq", "adj.rsq"))
```

Models 1 and 2 estimate buyers' perception of sellers' competence based on the
same pooled covariates mentioned in Table 5. The only difference between Model 1
and Model 2 is that Model 2 also contains an interaction term between the
`political connection signal` and `formal contract` variables.

The interaction term difference is identical for Models 3 & 4, Models 5 & 6,
Models 7 & 8, and Models 9 & 10. Models 3 & 4 estimate sellers' perceived
trustworthiness to buyers. Models 5 & 6 estimate sellers' perceptions of the
number of questions the buyer asked during the transaction. Models 7 & 8
estimate buyers' politeness as perceived by the sellers. Models 9 & 10 estimate
buyers' level of suspiciousness to the transaction deal, as perceived by the
sellers.

Looking at the model outputs, we see that sellers were viewed by buyers as less
competent and trustworthy when they signaled political connections. This may be
due to the fact that buyers believe politically connected sellers will not be
held accountable if they cheat customers. Furthermore, buyers may also believe
that sellers gained employment via connections rather than merit. In contrast,
sellers were viewed by buyers as more competent and trustworthy when they
offered formal contracts. This could be due to mandatory business contracts
serving a role of signaling that the seller is serious about their business
(after all, people may think a lazy seller or cheater wouldn't go through such a
hassle).

On the buyer side, we see that buyers were on average more likely to ask
questions during the transaction when sellers' signaled having political
connections compared to instances where sellers did not signal having political
connections. This makes sense as buyers may feel more uncomfortable dealing with
a politically connected seller, which would cause them to conduct more in-depth
examination of the service the buyers are considering purchasing. Furthermore,
buyers were on average more likely to ask questions during the transaction when
sellers' required formal contract compared to instances where sellers did not
require formal contracts. Buyers were also more likely to be suspicious of the
deal with sellers signaled their political connections (for similar reasons
discussed above).

Although I was able to replicate every part of this paper when exploring the
data, for the scope of this replication, I decided to exclude several
descriptive figures and two figures that examined how buyers' connections
influenced the exchange of goods. This was because Bhandari's paper is quite
lengthy, so I felt it would be best to focus my efforts on replicating one core
part of it, which pertained to how sellers' behavior (e.g., signaling political
connections and offering formal contracts) affect buyers' willingness to
purchase goods and engage in various levels of risk in their transactions.

# Limitations of the Original Analysis + Proposed Extension

One thing I noticed was that Bhandari used mean imputation to impute missing
values. But this is not a good method to impute missing values because it
reduces the standard errors, which creates problems for hypothesis tests and
confidence interval calculations (Wicklin SAS).

To avoid such problems, for my project's extension, I decided to use multiple
imputation to fill in missing data (via MICE). First, I undid all of Bhandari's
mean imputations for the variables (see Figure A).

```{r mice, results = 'asis', warning = FALSE, message = FALSE, fig.pos="H"}

# Changing all imputed values back to NA

# Education
data_for_mice$educ_level[data_for_mice$educ_level==98 | data_for_mice$educ_level == 99
                       | data_for_mice$missing_endline==1] <- NA

# Age
data_for_mice$descriptives.age[data_for_mice$descriptives.age==0 | data_for_mice$descriptives.age ==3 | 
                        data_for_mice$missing_endline==1] <- NA

# Student
data_for_mice$student[data_for_mice$missing_endline==1] <- NA

# Employed
data_for_mice$employed[data_for_mice$missing_endline==1] <- NA

# Coethnic or coreligious
data_for_mice$coethnicreligion[data_for_mice$missing_endline==1] <- NA

# belief in sellers' connections
data_for_mice$thinks_seller_is_connected[data_for_mice$thinks_seller_is_connected > 3 | is.na(data_for_mice$thinks_seller_is_connected)==T] <- NA

empty_variables <- subset(data_for_mice, select = c("educ_level", 
                                                    "descriptives.age", 
                                           "student", "employed", 
                                           "coethnicreligion",
                                           "thinks_seller_is_connected"))

# Creating a table to show how empty these variables are
empty_variable_t <- colSums(is.na(empty_variables))/nrow(empty_variables)

kable(empty_variable_t, 
      caption = "Figure A: Proportion of NA Values in Original Data",
      col.names = "Proportion of NA Values") %>%
  kable_styling(font_size = 8,
                latex_options = "hold_position")
```


```{r miceimputation, results = 'asis', warning = FALSE, message = FALSE}

# Multiple imputation

colnames(data_for_mice) <- str_replace(colnames(data_for_mice), ":", "_")
                                         
invisible(capture.output(mice_data <- mice(data_for_mice, 3, seed=123, 
                                           nnet.MaxNWts = 3000)))

newdf <- complete(mice_data, action = 1)
```


```{r miceimputation2, results = 'asis', warning = FALSE, message = FALSE}

# Model A - Mice: Purchased at all (unpooled)
mice_model_a <- lm(purchased ~ T1 + T2 + T3 + T1*T2 + T1*T3 + gender + blockid + 
                enum + descriptives.age + employed + student + educ_level +
                coethnicreligion*T1 + coethnicreligion*T2 + coethnicreligion*T3, 
              data = newdf)


# Model B - Mice: Purchased at all (pooled)
newdff <- subset(newdf, select = c("pool_T1", "pool_T2", "gender", 
                                                 "blockid", "enum", 
                                                 "descriptives.age", "employed",
                                                 "student", "educ_level",
                                                 "coethnicreligion", 
                                                 "purchased",
                                                 "subscription_trust")) %>%
  mutate(T1 = pool_T1,
         T2 = pool_T2)

mice_model_b <- lm(purchased ~ T1 + T2 + T1*T2 + gender + blockid + 
                enum + descriptives.age + employed + student + educ_level +
                coethnicreligion*T1 + coethnicreligion*T2, 
              data = newdff)

# Model C: Purchased with delay (unpooled)
mice_model_c <- lm(subscription_trust ~ T1 + T2 + T3 + T1*T2 + T1*T3 + gender + 
              blockid + enum + descriptives.age + employed + student + 
              educ_level + coethnicreligion*T1 + coethnicreligion*T2 + 
              coethnicreligion*T3, data = newdf)

# Model D: Purchased with delay (pooled)
mice_model_d <- lm(subscription_trust ~ T1 + T2 + T1*T2 + 
                gender + blockid + 
                enum + descriptives.age + employed + student + educ_level +
                coethnicreligion*T1 + coethnicreligion*T2, 
              data = newdff)
```

I then used `mice` to fill the NA values via multi-imputation. I then ran the
same model done on Table 5 on the mice dataset and compared it to Bhandari's
original results. Below, Table 5a refers to the original table in the paper, and
Table 5b refers to the table with MICE models.

```{r miceimputation3, results = 'asis', warning = FALSE}

# Original Table 5
stargazer(model_a, model_b, model_c, model_d,
          title = "Table 5a: Average Treatment Effects",
          covariate.labels = c("Political connection signaled",
                               "Required contract",
                               "Optional contract",
                               "Political connection signal x required contract",
                               "Political connection signal x optional contract"),
          omit = c("gender", "blockid", "enum", "descriptives.age",  
                   "employed","student", "educ_level","coethnicreligion",
                   "Constant"),
          column.labels = c("Unpooled", 
                            "Pooled",
                            "Unpooled",
                            "Pooled"),
          dep.var.labels = c("Purchased at all", 
                             "Purchased with Delay"),
          header = FALSE,
          single.row = FALSE, 
          no.space = FALSE, 
          column.sep.width = "2pt",
          font.size = "small",
          omit.stat=c("ser","f", "ll","rsq", "adj.rsq"))

# MICE Table 5
stargazer(mice_model_a, mice_model_b, mice_model_c, mice_model_d,
          table.placement = "H",
          title = "Table 5b: Average Treatment Effect (MICE)",
          covariate.labels = c("Political connection signaled",
                               "Required contract",
                               "Optional contract",
                               "Political connection signal x required contract",
                               "Political connection signal x optional contract"),
          omit = c("gender", "blockid", "as.factor", "enum", "descriptives.age",  
                   "employed","student", "educ_level","coethnicreligion",
                   "Constant"),
          column.labels = c("Unpooled", 
                            "Pooled",
                            "Unpooled",
                            "Pooled"),
          dep.var.labels = c("Purchased at all", 
                             "Purchased with Delay"),
          font.size = "small",
          single.row = FALSE, 
          no.space = FALSE, 
          column.sep.width = "2pt",
          header = FALSE,
          omit.stat=c("ser","f", "ll","rsq", "adj.rsq"))

```

\newpage

Comparing Tables 5a and 5b, it seems that, overall, model outputs from the mean
imputation and multi-imputation data agree on the effects of political signaling
and formal contracts on the exchange of goods in countries with weak legal
institutions such as Senegal. Both models show that sellers' signaling political
connections on average decreased the likelihood of buyers making a purchase
compared to instances where sellers' did not signal political connections..

Furthermore, both models showed that sellers' requiring a contract on average
increased the likelihood of a buyer making a purchase (as well as the likelihood
of a buyer making a riskier purchase) compared to when sellers did not mandate a
formal contract.

While these two models overall tell the same narrative about the impact of
political connections and contracts, it is important to note that the model
coefficients between the mean imputation model and the multi-imputation model
were noticeably different. 

In particular, we should pay attention to the coefficient of the `required
contract` variable for the unpooled, purchased with delay model. For Bhandari's
model, this coefficient (-0.104) has a standard error of 0.037, meaning the
coefficient is around 2.81 standard errors from zero. Meanwhile, the same
variable in multi-imputation model has a coefficient value of 0.093 with a 0.037
standard error. That means this coefficient is around 2.51 standard errors from
zero, which is a somewhat substantial change from Bhandari's original results.

More alarming is the `required contract` variable in the pool, purchased with
delay model. With the mean imputation data, this variable has a coefficient of
0.075 and a 0.032 standard error, which means the coefficient is 2.34 standard
errors away from zero. However, with the multi-imputation data, this same
variable has a coefficient of 0.066 and a 0.032 standard error, which means the
coefficient is only 2.06 standard errors away from zero.. A 2.06 standard
deviation borders on a variable not being significant in conventional modeling
terms (i.e., a >= 1.96 standard error is the cut-off for a p value of < 0.05).

The difference in standard errors from zero for the same variable is important
to note, because coefficient significance can play a large role in what factors
we consider to be important in a variable relationship. Thus, the difference
between the mice and mean models demonstrates how we need to be careful when
choosing how to impute missing values.


# Conclusion

In this project, I walked the reader through Abhit Bhandari's experiment that
explores how political connections and formal contracts impact the exchange of
goods in countries with weak legal institutions such as Senegal. I accurately
replicated 2 descriptive figures showcasing the experiment design as well as 3
additional tables that encompassed a cumulative 15 models.

The first table served to validate Bhandari's methodology of having sellers
convince buyers that the seller held political connections, via the seller's
mentioning prior work experience with a municipal council. The second table
estimated the average treatment effect for experiment subjects that were subject
to a certain permutation of treatments (including political connection signal,
contract requirement, and optional contract offering) in regards to two
different outcome variables (if the buyer purchased anything at all and if the
buyer purchased a product that entailed a delay in its delivery). The third
table estimated certain quality measures such as sellers' competence, sellers'
trustworthiness, and buyers' inquisitiveness, and buyer politeness, among
others.

Ultimately, I arrived at the same conclusions at Bhandari. Sellers' signaling
political connections was associated with a negative impact on buyers'
willingness to purchase goods from the seller. Additionally, the presence of
mandatory formal contracts was associated with buyers being more willing to
purchase higher-risk products.

Finally, I extended my models measuring the impact of political connections and
formal contracts on buyers' willingness to purchase goods (and their willingness
to purchase risky products) by running models on data with multi-imputation
instead of Bhandari's mean imputation.

# Additional References

"An Informal Introduction to Factorial Experimental Designs." Penn State College
of Health and Human Development. 7 May 2020.
https://www.methodology.psu.edu/ra/most/factorial/. Last Accessed 6 May 2021.

Bhandari, A. (2021), Political Determinants of Economic Exchange: 
Evidence from a Business Experiment in Senegal. American Journal of Political 
Science. https://doi.org/10.1111/ajps.12593

Suresh K. (2011). An overview of randomization techniques: An unbiased 
assessment of outcome in clinical research. Journal of human reproductive 
sciences, 4(1), 811. https://doi.org/10.4103/0974-1208.82352.

Wicklin, Rick. "3 problems with mean imputation." SAS. 6 December 2017.
https://blogs.sas.com/content/iml/2017/12/06/problems-mean-imputation.html.
Last Accessed 6 May 2021.
